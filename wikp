#!/usr/local/bin/node

// Returns the paragraphs from a Wikipedia link, stripped of reference numbers.

let request = require("request");
let url = process.argv[2];
let fs = require('fs');


if (!url){
	console.log('a url is needed to scrape..');
	console.log('re-enter..');
	console.log('wikp <your url>');
	process.exit(9);
}

const jsdom = require("jsdom");
const { JSDOM } = jsdom;

request(url, function(error, response, body) {

	  // Simulate a Document Object Model.
	  let { document } = (new JSDOM(body)).window;

	  // Grab all the paragraphs and references.
	  let paragraphs = document.querySelectorAll("p");
	  let references = document.querySelectorAll(".reference");

	  // Remove any references.
	  references.forEach(function(reference) {
	    reference.remove();
	  });

	  // write to .txt file using last part of url as title.
	  paragraphs.forEach(function(paragraph) {
	  	let fileName = url.split('/').pop().toLowerCase().concat('-','article.txt');
	  	fs.appendFile(`${fileName}`, `${paragraph.textContent}\n`, (err) => {  
	  		if (err) throw err;
	  		console.log('paragraph added!');
	  		});
	  });
});